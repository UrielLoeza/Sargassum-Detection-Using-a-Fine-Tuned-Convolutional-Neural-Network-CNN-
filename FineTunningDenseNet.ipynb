{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "# Extract ZIP file\n",
        "uploaded_zip_path = '/content/clasifica-el-sargazo-24-b.zip'\n",
        "extract_path = '/content/clasifica-el-sargazo'\n",
        "with zipfile.ZipFile(uploaded_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Load CSV files\n",
        "train_csv_path = os.path.join(extract_path, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(extract_path, \"test_data.csv\")\n",
        "images_path = \"/content/clasifica-el-sargazo/images_public/images_public\"\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Function to augment images and update them in the DataFrame\n",
        "def augment_images(class_name, target_count, datagen, train_df, images_path, target_size=(224, 224)):\n",
        "    current_count = train_df[train_df['Category'] == class_name].shape[0]\n",
        "    augmentation_needed = target_count - current_count\n",
        "    if augmentation_needed <= 0:\n",
        "        return train_df\n",
        "\n",
        "    # Filter existing images of the class\n",
        "    class_images = train_df[train_df['Category'] == class_name]\n",
        "    augmented_rows = []\n",
        "\n",
        "    for _, row in class_images.iterrows():\n",
        "        if augmentation_needed <= 0:\n",
        "            break\n",
        "\n",
        "        image_path = os.path.join(images_path, row['Id'])\n",
        "        img = tf.keras.utils.load_img(image_path, target_size=target_size)\n",
        "        img_array = tf.keras.utils.img_to_array(img)  # Convert to array\n",
        "\n",
        "        # Expand dimensions for compatibility with the generator\n",
        "        img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "        # Generate augmented images and save them\n",
        "        for batch in datagen.flow(img_array, batch_size=1):\n",
        "            augmented_img_name = f\"augmented_{class_name}_{augmentation_needed}.jpg\"\n",
        "            augmented_img_path = os.path.join(images_path, augmented_img_name)\n",
        "            tf.keras.utils.save_img(augmented_img_path, batch[0])\n",
        "            augmented_rows.append({'Id': augmented_img_name, 'Category': class_name})\n",
        "            augmentation_needed -= 1\n",
        "            if augmentation_needed <= 0:\n",
        "                break  # Stop generation if target is reached\n",
        "\n",
        "    # Concatenate new data to the original DataFrame\n",
        "    return pd.concat([train_df, pd.DataFrame(augmented_rows)], ignore_index=True)\n",
        "\n",
        "# Create augmentation generator for minority classes\n",
        "augmentation_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Augment images for each minority class\n",
        "minor_classes = ['moderado', 'abundante', 'excesivo']  # Adjust according to your classes\n",
        "target_count = 500  # Increase to 500 images per class\n",
        "for class_name in minor_classes:\n",
        "    train_df = augment_images(class_name, target_count, augmentation_datagen, train_df, images_path)\n",
        "\n",
        "# Check the total number of images in the DataFrame\n",
        "print(f\"Total images in the DataFrame: {len(train_df)}\")\n",
        "\n",
        "# Create data generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=images_path,\n",
        "    x_col='Id',\n",
        "    y_col='Category',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=images_path,\n",
        "    x_col='Id',\n",
        "    y_col='Category',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 1. Load the base DenseNet201 model and freeze layers\n",
        "base_model = DenseNet201(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
        "base_model.trainable = False\n",
        "\n",
        "# 2. Create the full model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(6, activation='softmax')  # Change the number according to your classes\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Train the top layers\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
        ")\n",
        "\n",
        "# 5. Unfreeze the base model layers\n",
        "base_model.trainable = True\n",
        "\n",
        "# 6. Set a lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 7. Train with fine-tuning\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
        ")\n",
        "\n",
        "# Prepare test data\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=images_path,\n",
        "    x_col='Id',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Generate predictions\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}  # Invert mapping\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = [class_indices[idx] for idx in predictions.argmax(axis=1)]\n",
        "\n",
        "# Assign predictions to the DataFrame\n",
        "test_df['prediction'] = predicted_classes\n",
        "\n",
        "# Save the predictions file\n",
        "output_csv_path = \"/content/clasifica-el-sargazo-submission.csv\"\n",
        "test_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Predictions file saved at: {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FliXYLEahd_j",
        "outputId": "f855d414-ea4e-4982-bb83-d852ab00cf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes en el DataFrame: 3395\n",
            "Found 2716 validated image filenames belonging to 6 classes.\n",
            "Found 679 validated image filenames belonging to 6 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 977ms/step - accuracy: 0.5039 - loss: 2.7527 - val_accuracy: 0.5670 - val_loss: 1.1486\n",
            "Epoch 2/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 369ms/step - accuracy: 0.6398 - loss: 0.8967 - val_accuracy: 0.5538 - val_loss: 1.1010\n",
            "Epoch 3/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 392ms/step - accuracy: 0.6607 - loss: 0.8319 - val_accuracy: 0.5434 - val_loss: 1.1042\n",
            "Epoch 4/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 364ms/step - accuracy: 0.6678 - loss: 0.8292 - val_accuracy: 0.5449 - val_loss: 1.1556\n",
            "Epoch 5/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 397ms/step - accuracy: 0.6717 - loss: 0.8431 - val_accuracy: 0.5449 - val_loss: 1.1392\n",
            "Epoch 1/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 4s/step - accuracy: 0.6152 - loss: 0.9874 - val_accuracy: 0.4845 - val_loss: 1.8159\n",
            "Epoch 2/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 581ms/step - accuracy: 0.7116 - loss: 0.7828 - val_accuracy: 0.6289 - val_loss: 0.9897\n",
            "Epoch 3/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 598ms/step - accuracy: 0.7646 - loss: 0.6331 - val_accuracy: 0.6259 - val_loss: 1.0384\n",
            "Epoch 4/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 608ms/step - accuracy: 0.7832 - loss: 0.5983 - val_accuracy: 0.6598 - val_loss: 0.9391\n",
            "Epoch 5/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 617ms/step - accuracy: 0.8178 - loss: 0.5230 - val_accuracy: 0.6672 - val_loss: 1.0011\n",
            "Epoch 6/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 619ms/step - accuracy: 0.8166 - loss: 0.5066 - val_accuracy: 0.6627 - val_loss: 1.1875\n",
            "Epoch 7/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 607ms/step - accuracy: 0.8530 - loss: 0.4283 - val_accuracy: 0.6613 - val_loss: 1.0019\n",
            "Epoch 8/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 597ms/step - accuracy: 0.8652 - loss: 0.4053 - val_accuracy: 0.6760 - val_loss: 0.9921\n",
            "Epoch 9/50\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 609ms/step - accuracy: 0.8783 - loss: 0.3650 - val_accuracy: 0.6539 - val_loss: 1.2273\n",
            "Found 272 validated image filenames.\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 160ms/step\n",
            "Archivo de predicciones guardado en: /content/clasifica-el-sargazo-submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Seo0jow7uk81",
        "outputId": "9ebddc01-c96c-435a-96a3-109b9fdb4aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category\n",
            "nada         1167\n",
            "bajo          703\n",
            "moderado      225\n",
            "excesivo      178\n",
            "abundante     147\n",
            "excesivo       25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_df['Category'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKAwuHvOirY7"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}